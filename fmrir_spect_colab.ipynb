{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "455DrTfig4Vt",
        "outputId": "d147d2e7-a8fc-41a1-e469-f6a4c87c41a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "\n",
        "# Log in to your W&B account\n",
        "import wandb\n",
        "import random\n",
        "import math\n",
        "\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "id": "diR6u8fHq2Px"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List contents of your Drive\n",
        "#import os\n",
        "#os.listdir('/content/drive/My Drive/')\n",
        "\n",
        "# Load a file from your Drive\n",
        "#with open('/content/drive/My Drive/FMRIR/fm_utils.py', 'r') as f:\n",
        "    #content = f.read()\n",
        "\n",
        "# Save a file to your Drive\n",
        "#with open('/content/drive/My Drive/new_file.txt', 'w') as f:\n",
        "    #f.write('This is a new file saved from Colab.')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/FMRIR')\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "from fm_utils import (\n",
        "    SpectrogramSampler, GaussianConditionalProbabilityPath, LinearAlpha,\n",
        "    LinearBeta, CFGTrainer, SpecUNet\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EFFg_8shFrR",
        "outputId": "8b68edd3-8cad-45ca-c48e-2c6dc0dab740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Başlıksız form.gform',\n",
              " 'IS100-ProfExam-Monday.xlsx',\n",
              " 'IS100-ProfExam-Monday.gsheet',\n",
              " '369bce03.png',\n",
              " 'Yurt İçi ve Yurt Dışında Öğretim Elemanı ve Araştırmacı Destekleme Programlarına İlişkin Usul ve Esaslar.pdf',\n",
              " '2202304-3329.pdf',\n",
              " 'M2192- Use Cases and Functional Requirements - Six DoF Audio (CAE-6DA) WD0.1.1.docx',\n",
              " 'cool, what changes do we need for u-net? preservi...',\n",
              " 'ir_fs2000_s1024_m1331_room4.0x6.0x3.0_rt200',\n",
              " 'Colab Notebooks',\n",
              " 'FMRIR']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- Configuration ---\n",
        "config = {\n",
        "    \"data\": {\n",
        "        \"data_dir\": \"/content/drive/My Drive/ir_fs2000_s1024_m1331_room4.0x6.0x3.0_rt200/\",\n",
        "        \"src_splits\": {\n",
        "            \"train\": [0, 820],\n",
        "            \"valid\": [820, 922],\n",
        "            \"test\": [922, 1024],\n",
        "            \"all\": [0, 1024]}\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"name\": \"SpecUNet\",\n",
        "        \"channels\": [32, 64, 128],\n",
        "        \"num_residual_layers\": 2,\n",
        "        \"t_embed_dim\": 40,\n",
        "        \"y_dim\": 6,\n",
        "        \"y_embed_dim\": 40\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"num_epochs\": 10,\n",
        "        \"batch_size\": 250,\n",
        "        \"lr\": 1e-3,\n",
        "        \"eta\": 0.1\n",
        "    },\n",
        "    \"experiments_dir\": \"/content/drive/MyDrive/FMRIR\"\n",
        "}\n",
        "\n",
        "# --- Experiment Setup ---\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "experiment_name = f\"{config['model']['name']}_{timestamp}\"\n",
        "experiment_dir = os.path.join(config['experiments_dir'], experiment_name)\n",
        "os.makedirs(experiment_dir, exist_ok=True)\n",
        "\n",
        "MODEL_SAVE_PATH = os.path.join(experiment_dir, \"model.pt\")\n",
        "#CONFIG_SAVE_PATH = os.path.join(experiment_dir, \"config.json\")\n",
        "\n"
      ],
      "metadata": {
        "id": "S6CmWdrfg1sj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    # Set the wandb entity where your project will be logged (generally your team name).\n",
        "    entity=\"ege-erdem-king-s-college-london\",\n",
        "    # Set the wandb project where this run will be logged.\n",
        "    project=\"FM-RIR\",\n",
        "    # Track hyperparameters and run metadata.\n",
        "    config=config\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "POGMl6wSrVex",
        "outputId": "de5d9301-0ccb-4a69-b587-eb87b680a4d3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dauntless-sponge-1</strong> at: <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/2dprhwcm' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/2dprhwcm</a><br> View project at: <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250730_094849-2dprhwcm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250730_094956-axavz1wl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/axavz1wl' target=\"_blank\">sandy-firebrand-2</a></strong> to <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/axavz1wl' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/axavz1wl</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Loading ---\n",
        "data_cfg = config['data']\n",
        "temp_sampler = SpectrogramSampler(data_path=data_cfg['data_dir'], mode=\"all\", src_splits=data_cfg['src_splits'])\n",
        "\n",
        "spec_mean = temp_sampler.spectrograms.mean()\n",
        "spec_std = temp_sampler.spectrograms.std()\n",
        "\n",
        "spec_train_sampler = SpectrogramSampler(\n",
        "    data_path=data_cfg['data_dir'], mode='train', src_splits=data_cfg['src_splits'],\n",
        "    transform=transforms.Compose([transforms.Normalize((spec_mean,), (spec_std,))])\n",
        ").to(device)\n",
        "\n",
        "sample_spec, _ = spec_train_sampler.sample(1)\n",
        "spec_shape = list(sample_spec.shape[1:])\n",
        "\n",
        "path = GaussianConditionalProbabilityPath(\n",
        "    p_data=spec_train_sampler, #was [1, 32, 32], for mnist\n",
        "    p_simple_shape=spec_shape,\n",
        "    alpha=LinearAlpha(),\n",
        "    beta=LinearBeta()\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# --- Model and Trainer Initialization ---\n",
        "model_cfg = config['model']\n",
        "training_cfg = config['training']\n",
        "\n",
        "spec_unet = SpecUNet(\n",
        "    channels=model_cfg['channels'], # Same as MNIST version\n",
        "    num_residual_layers=model_cfg['num_residual_layers'], # Same as MNIST version\n",
        "    t_embed_dim=model_cfg['t_embed_dim'], # Same as MNIST version\n",
        "    y_dim=model_cfg['y_dim'], # new: 6D coordinates for source and microphone positions\n",
        "    y_embed_dim=model_cfg['y_embed_dim'], # Same as MNIST version\n",
        ").to(device)\n",
        "\n",
        "trainer = CFGTrainer(\n",
        "    path=path,\n",
        "    model=spec_unet,\n",
        "    eta=training_cfg['eta'],\n",
        "    y_dim=model_cfg['y_dim'],\n",
        ")\n",
        "\n",
        "# --- Training ---\n",
        "print(f\"--- Starting Training for experiment: {experiment_name} ---\")\n",
        "trainer.train(\n",
        "    num_epochs=training_cfg['num_epochs'],\n",
        "    device=device,\n",
        "    lr=training_cfg['lr'],\n",
        "    batch_size=training_cfg['batch_size']\n",
        ")\n",
        "\n",
        "# --- Save the Model ---\n",
        "print(f\"Saving model to {MODEL_SAVE_PATH}...\")\n",
        "torch.save({\n",
        "    'model_state_dict': spec_unet.state_dict(),\n",
        "    'y_null': trainer.y_null,\n",
        "    'config': config # Save config with model for easy reference\n",
        "}, MODEL_SAVE_PATH)\n",
        "print(\"Model saved. You can now run inference using the model and config from the experiment directory.\")\n",
        "print(f\"Experiment directory: {experiment_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcjX9kLSjpx5",
        "outputId": "124c61cd-566f-440f-c77f-bf02e7d39c7f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-processed all data from /content/drive/My Drive/ir_fs2000_s1024_m1331_room4.0x6.0x3.0_rt200/processed_all.pt\n",
            "Loaded 21296 spectrograms for all set.\n",
            "Spectrogram tensor shape: torch.Size([21296, 16, 16])\n",
            "Coordinate tensor shape: torch.Size([21296, 6])\n",
            "Loading pre-processed train data from /content/drive/My Drive/ir_fs2000_s1024_m1331_room4.0x6.0x3.0_rt200/processed_train.pt\n",
            "Loaded 1091420 spectrograms for train set.\n",
            "Spectrogram tensor shape: torch.Size([1091420, 16, 16])\n",
            "Coordinate tensor shape: torch.Size([1091420, 6])\n",
            "--- Starting Training for experiment: SpecUNet_20250730-094954 ---\n",
            "Training model with size: 4.721 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1, loss: 787.228: : 2it [00:02,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 639.167\n",
            "Epoch 1, loss: 787.228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3, loss: 614.428: : 4it [00:02,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, loss: 1124.957\n",
            "Epoch 3, loss: 614.428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6, loss: 402.356: : 6it [00:02,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, loss: 539.184\n",
            "Epoch 5, loss: 412.349\n",
            "Epoch 6, loss: 402.356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9, loss: 375.009: : 10it [00:03,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, loss: 391.082\n",
            "Epoch 8, loss: 372.250\n",
            "Epoch 9, loss: 375.009\n",
            "Saving model to /content/drive/MyDrive/FMRIR/SpecUNet_20250730-094954/model.pt...\n",
            "Model saved. You can now run inference using the model and config from the experiment directory.\n",
            "Experiment directory: /content/drive/MyDrive/FMRIR/SpecUNet_20250730-094954\n"
          ]
        }
      ]
    }
  ]
}